{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06f1534",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1152bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    segment_and_renumber,\n",
    "    haversine_m,\n",
    "    create_mmsi_dict_from_file\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d76a4",
   "metadata": {},
   "source": [
    "# Fecthing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "656b94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Successfully created dictionary ---\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/mmsi_type.txt\"\n",
    "mmsi_map = create_mmsi_dict_from_file(file_name)\n",
    "\n",
    "if mmsi_map:\n",
    "    print(\"--- Successfully created dictionary ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff3db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ais_combined_merged.csv\")\n",
    "df_with_types = df.copy()\n",
    "df_with_types['Type'] = df_with_types['MMSI'].astype(str).map(mmsi_map)\n",
    "allowed_type = ['Cargo ship', 'Cargo ship (HAZ-A)', 'Cargo ship (HAZ-B)', 'Cargo ship (HAZ-D)', 'Tanker', 'Tanker (HAZ-A)', 'Tanker (HAZ-B)', 'Tanker (HAZ-C)', 'Tanker (HAZ-D)']\n",
    "df_cargo = df_with_types[df_with_types['Type'].isin(allowed_type)]\n",
    "\n",
    "df_cargo = df_cargo.drop(columns=[\"Type\"], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c4d52",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91afd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "GAP_BREAK_MIN = 180\n",
    "INTERPOLATION_LIMIT_MIN = 3\n",
    "MAX_DISTANCE_M = 3000 # meters\n",
    "MAX_SOG_KNOTS = 40 * 0.514444  # Convert knots to m/s\n",
    "NUM_COLS = [\"SOG\", \"COG\", \"Longtitude\", \"Latitude\"]\n",
    "MIN_SEGMENT_LENGTH = 35\n",
    "INTERVAL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ceb193",
   "metadata": {},
   "source": [
    "### Check Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5f676ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (1737515, 7)\n",
      "Data types:\n",
      "MMSI                   int64\n",
      "SOG                  float64\n",
      "COG                  float64\n",
      "Longtitude           float64\n",
      "Latitude             float64\n",
      "Timestamp     datetime64[ns]\n",
      "Segment                int64\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cargo = df_cargo.sort_values([\"MMSI\", \"Timestamp\"]).reset_index(drop=True)\n",
    "df_cargo[\"Timestamp\"] = pd.to_datetime(df_cargo[\"Timestamp\"], errors=\"coerce\")\n",
    "print(f\"Initial data shape: {df_cargo.shape}\")\n",
    "print(f\"Data types:\\n{df_cargo.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d01586",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8234ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = segment_and_renumber(df_cargo, GAP_BREAK_MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d7976",
   "metadata": {},
   "source": [
    "### Downsampling & interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7f4269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (70343, 8)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for (mmsi, seg), g in df.groupby([\"MMSI\", \"Segment\"]):\n",
    "    g = g.set_index(\"Timestamp\")\n",
    "\n",
    "    g1 = g.resample(f\"{INTERVAL}min\").last()\n",
    "    \n",
    "    # Cubic spline interpolation\n",
    "    non_null_counts = g1[NUM_COLS].notnull().sum()\n",
    "    min_points = non_null_counts.min()\n",
    "    if min_points >= 4:\n",
    "        g1_numeric_idx = g1.copy()\n",
    "        g1_numeric_idx.index = (g1_numeric_idx.index - g1_numeric_idx.index[0]).total_seconds()\n",
    "\n",
    "        g1_numeric_idx[NUM_COLS] = g1_numeric_idx[NUM_COLS].interpolate(\n",
    "            method=\"spline\", order=3, limit=INTERPOLATION_LIMIT_MIN, limit_direction=\"both\"\n",
    "        )\n",
    "\n",
    "        g1[NUM_COLS] = g1_numeric_idx[NUM_COLS].values\n",
    "    else:\n",
    "        g1[NUM_COLS] = g1[NUM_COLS].interpolate(\n",
    "            method=\"linear\", limit=INTERPOLATION_LIMIT_MIN, limit_direction=\"both\"\n",
    "        )\n",
    "\n",
    "    g1 = g1.dropna(subset=NUM_COLS, how=\"any\")\n",
    "    \n",
    "    if len(g1) < 1:\n",
    "        continue\n",
    "    \n",
    "    g1[\"COG\"] = g1[\"COG\"] % 360\n",
    "    \n",
    "    g1[\"MMSI\"] = mmsi\n",
    "    g1[\"Segment\"] = seg\n",
    "\n",
    "    lat = g1[\"Latitude\"].to_numpy()\n",
    "    lon = g1[\"Longtitude\"].to_numpy()\n",
    "    lat_prev = np.roll(lat, 1)\n",
    "    lon_prev = np.roll(lon, 1)\n",
    "\n",
    "    g1[\"distance_m\"] = haversine_m(lat, lon, lat_prev, lon_prev)\n",
    "    g1.loc[g1.index[0], \"distance_m\"] = 0.0\n",
    "    \n",
    "    g1 = g1[(g1[\"distance_m\"] <= MAX_DISTANCE_M) & (g1[\"SOG\"] <= MAX_SOG_KNOTS)]\n",
    "\n",
    "    results.append(g1)\n",
    "\n",
    "df_clean = pd.concat(results).reset_index()\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e77716",
   "metadata": {},
   "source": [
    "### Data quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b98188d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 70343\n",
      "Rows with missing numeric data: 0 (0.00%)\n",
      "MMSI with missing data: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows before cleaning: {len(df_clean)}\")\n",
    "\n",
    "missing = df_clean[df_clean[NUM_COLS].isna().any(axis=1)]\n",
    "print(f\"Rows with missing numeric data: {len(missing)} ({len(missing)/len(df_clean)*100:.2f}%)\")\n",
    "print(f\"MMSI with missing data: {missing['MMSI'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfcfecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning: 70343\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean.dropna(subset=NUM_COLS+[\"MMSI\", \"Segment\"])\n",
    "print(f\"Rows after cleaning: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eabe47",
   "metadata": {},
   "source": [
    "### Re-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68fffdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re-segmenting based on gaps > 5 minutes\n",
      "Maximum time gap after re-segmentation: 5.00 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nRe-segmenting based on gaps > {INTERVAL} minutes\")\n",
    "df_clean = df_clean.sort_values([\"MMSI\", \"Segment\", \"Timestamp\"]).reset_index(drop=True)\n",
    "df_clean = segment_and_renumber(df_clean, GAP_BREAK_MIN=5)\n",
    "\n",
    "max_gap_after = df_clean.groupby([\"MMSI\",\"Segment\"])[\"Timestamp\"].diff().dt.total_seconds().div(60).max()\n",
    "print(f\"Maximum time gap after re-segmentation: {max_gap_after:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e24a4",
   "metadata": {},
   "source": [
    "### Segment length filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c5c7522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering segments with < 35 points\n",
      "Segments before filtering: 873\n",
      "Rows before filtering: 70343\n",
      "Segments after filtering: 388\n",
      "Rows after filtering: 67102\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFiltering segments with < {MIN_SEGMENT_LENGTH} points\")\n",
    "print(f\"Segments before filtering: {df_clean.groupby(['MMSI', 'Segment']).ngroups}\")\n",
    "print(f\"Rows before filtering: {len(df_clean)}\")\n",
    "\n",
    "segment_sizes = df_clean.groupby([\"MMSI\", \"Segment\"]).size()\n",
    "valid_segments = segment_sizes[segment_sizes >= MIN_SEGMENT_LENGTH].index\n",
    "df_clean = df_clean.set_index([\"MMSI\", \"Segment\"]).loc[valid_segments].reset_index()\n",
    "\n",
    "print(f\"Segments after filtering: {df_clean.groupby(['MMSI', 'Segment']).ngroups}\")\n",
    "print(f\"Rows after filtering: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8154fd7",
   "metadata": {},
   "source": [
    "### Dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "596df101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 67102\n",
      "Unique vessels (MMSI): 272\n",
      "Total segments: 388\n",
      "Average segment length: 864.7 minutes\n",
      "Columns: ['MMSI', 'Segment', 'Timestamp', 'SOG', 'COG', 'Longtitude', 'Latitude', 'distance_m']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows: {len(df_clean)}\")\n",
    "print(f\"Unique vessels (MMSI): {df_clean['MMSI'].nunique()}\")\n",
    "print(f\"Total segments: {df_clean.groupby(['MMSI', 'Segment']).ngroups}\")\n",
    "print(f\"Average segment length: {df_clean.groupby(['MMSI', 'Segment']).size().mean()*INTERVAL:.1f} minutes\")\n",
    "print(f\"Columns: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e8863",
   "metadata": {},
   "source": [
    "### Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3c7ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to: data/ais_data_5min_clean.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = \"data/ais_data_5min_clean.csv\"\n",
    "df_clean.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"\\nCleaned data saved to: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
