{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27781256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install folium\n",
    "\n",
    "from utils import create_mmsi_dict_from_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf88706",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/mmsi_type.txt\"\n",
    "mmsi_map = create_mmsi_dict_from_file(file_name)\n",
    "\n",
    "\n",
    "if mmsi_map:\n",
    "    print(\"--- Successfully created dictionary ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33829c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ais_combined_merged.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fa552",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_with_types = df.copy()\n",
    "df_with_types['Type'] = df_with_types['MMSI'].astype(str).map(mmsi_map)\n",
    "df_with_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb85772",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mmsi = df['MMSI'].unique()\n",
    "unique_types = df_with_types['Type'].unique()\n",
    "\n",
    "print(\"Total unique MMSI count:\", len(unique_mmsi))\n",
    "print(\"Unique ship types in dataset:\", unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import filter_stationary_ships\n",
    "\n",
    "\n",
    "allowed_type = ['Cargo ship', 'Cargo ship (HAZ-A)', 'Cargo ship (HAZ-B)', 'Tanker']\n",
    "df_cargo = df_with_types[df_with_types['Type'].isin(allowed_type)]\n",
    "df_cargo = df_cargo.drop(columns=[\"Type\"], axis= 1)\n",
    "df_cargo.head()\n",
    "df_cargo_filtered = filter_stationary_ships(df_cargo) # This df has dropped stationary ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2600ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import segment_and_renumber, haversine_m\n",
    "\n",
    "GAP_BREAK_MIN = 10          # minutes to start a new segment\n",
    "INTERP_LIMIT_MIN = 5        # interpolate gaps up to 5 minutes\n",
    "MAX_DISTANCE_M = 3000       # ~97 knots\n",
    "MAX_SOG_KNOTS = 40\n",
    "OUTPUT_PATH = \"data/ais_data_1min_clean.csv\"\n",
    "NUM_COLS = [\"SOG\", \"COG\", \"Longtitude\", \"Latitude\"]\n",
    "# ---------------------------------------\n",
    "\n",
    "# --- Load data\n",
    "df_cargo = df_cargo.sort_values([\"MMSI\", \"Timestamp\"]).reset_index(drop=True)\n",
    "# --- Segment first (sequential per MMSI)\n",
    "# print(df_cargo)\n",
    "print(df_cargo.dtypes)\n",
    "df_cargo[\"Timestamp\"] = pd.to_datetime(df_cargo[\"Timestamp\"], errors=\"coerce\")\n",
    "df = segment_and_renumber(df_cargo, GAP_BREAK_MIN)\n",
    "\n",
    "# --- Downsample & interpolate per segment\n",
    "results = []\n",
    "for (mmsi, seg), g in df.groupby([\"MMSI\", \"Segment\"], observed=True):\n",
    "    g = g.set_index(\"Timestamp\")\n",
    "\n",
    "    # Downsample to 1-minute intervals (keep last)\n",
    "    g1 = g.resample(\"1min\").last()\n",
    "\n",
    "    # Interpolate numeric columns for short gaps only\n",
    "    g1[NUM_COLS] = g1[NUM_COLS].interpolate(\n",
    "        method=\"time\", limit=INTERP_LIMIT_MIN, limit_direction=\"both\"\n",
    "    )\n",
    "\n",
    "    # Drop minutes still NaN (beyond real range or long gaps)\n",
    "    g1 = g1.dropna(subset=NUM_COLS, how=\"all\")\n",
    "\n",
    "    # Fill identifiers\n",
    "    g1[\"MMSI\"] = mmsi\n",
    "    g1[\"Segment\"] = seg\n",
    "\n",
    "    # --- Outlier guards ---\n",
    "    lat = g1[\"Latitude\"].to_numpy()\n",
    "    lon = g1[\"Longtitude\"].to_numpy()\n",
    "    lat_prev, lon_prev = np.roll(lat, 1), np.roll(lon, 1)\n",
    "    lat_prev[0], lon_prev[0] = lat[0], lon[0]\n",
    "\n",
    "    g1[\"distance_m\"] = haversine_m(lat, lon, lat_prev, lon_prev)\n",
    "    g1.loc[g1.index[0], \"distance_m\"] = 0.0\n",
    "    g1[\"speed_mps_track\"] = g1[\"distance_m\"] / 60.0\n",
    "\n",
    "    # Filter unrealistic movement or SOG\n",
    "    g1 = g1[(g1[\"distance_m\"] < MAX_DISTANCE_M) & (g1[\"SOG\"] <= MAX_SOG_KNOTS)]\n",
    "\n",
    "    results.append(g1)\n",
    "\n",
    "\n",
    "# --- Combine & save\n",
    "df_clean = pd.concat(results).reset_index()\n",
    "print(\"Before deleting\", len(df_clean))\n",
    "missing = df_clean[df_clean[[\"SOG\", \"COG\", \"Latitude\", \"Longtitude\"]].isna().any(axis=1)]\n",
    "unique_mmsi_total = missing[\"MMSI\"].nunique()\n",
    "\n",
    "mmsi_ids_missing = missing[\"MMSI\"].unique()\n",
    "print(\"MMSI IDs with missing data:\")\n",
    "print(mmsi_ids_missing)\n",
    "\n",
    "\n",
    "print(\"Unique MMSI in full dataset:\", unique_mmsi_total)\n",
    "print(f\"Missing numeric data rows: {len(missing)}\")\n",
    "# Removing rows with empty data approximately 6%\n",
    "df_clean = df_clean.dropna(subset=[\"SOG\", \"COG\", \"Latitude\", \"Longtitude\", \"MMSI\", \"Segment\"])\n",
    "print(\"After deleting\", len(df_clean))\n",
    "\n",
    "print((df_clean.groupby([\"MMSI\",\"Segment\"])[\"Timestamp\"]\n",
    "   .diff().dt.total_seconds().div(60)\n",
    "   .max() > 5).any())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
