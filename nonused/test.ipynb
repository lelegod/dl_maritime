{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762a60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timestamp', 'Latitude', 'Longitude', 'SOG', 'COG', 'MMSI', 'Segment'] 6614370\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\parquet_data_2\")\n",
    "out_csv = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_28_02.csv\")\n",
    "\n",
    "# Force hive partition discovery so MMSI/Segment come in as columns\n",
    "dataset = ds.dataset(dataset_path, format=\"parquet\", partitioning=\"hive\")\n",
    "table = dataset.to_table()  # you can also add filter=... here\n",
    "df = table.to_pandas()\n",
    "\n",
    "# (Optional) ensure MMSI is string\n",
    "df[\"MMSI\"] = df[\"MMSI\"].astype(str)\n",
    "\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(df.columns.tolist(), len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923a28e",
   "metadata": {},
   "source": [
    "keep vessels from 00:00:00 to 12:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812a751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kept 3177925 rows (00:00:00 â†’ 12:00:00).\n",
      "ðŸ’¾ Saved to: C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_until12.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG ---\n",
    "csv_path = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_28_02.csv\")\n",
    "output_path = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_until12.csv\")\n",
    "\n",
    "\n",
    "# --- READ ---\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert 'Timestamp' column to datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "\n",
    "# Keep only rows where the time is between 00:00:00 and 12:00:00 (inclusive)\n",
    "mask = (df['Timestamp'].dt.hour < 12) | (\n",
    "    (df['Timestamp'].dt.hour == 12) & \n",
    "    (df['Timestamp'].dt.minute.eq(0)) & \n",
    "    (df['Timestamp'].dt.second.eq(0))\n",
    ")\n",
    "df_filtered = df[mask]\n",
    "\n",
    "# --- SAVE ---\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Kept {len(df_filtered)} rows (00:00:00 â†’ 12:00:00).\")\n",
    "print(f\"ðŸ’¾ Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa818f3a",
   "metadata": {},
   "source": [
    "keep only the vessels with id's in 27-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363e4b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered 3177925 â†’ 2119326 rows.\n",
      "ðŸ’¾ Saved to: C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_until12_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG ---\n",
    "file_1 = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_until12.csv\")  # file to filter\n",
    "file_2 = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\data\\ais_combined.csv\")  # file with reference MMSIs\n",
    "output = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_until12_filtered.csv\")\n",
    "\n",
    "# --- READ FILES ---\n",
    "df1 = pd.read_csv(file_1)   # the one you want to filter\n",
    "df2 = pd.read_csv(file_2)   # the reference file\n",
    "\n",
    "# --- FILTER: keep only rows where MMSI exists in both ---\n",
    "df_filtered = df1[df1[\"MMSI\"].isin(df2[\"MMSI\"])]\n",
    "\n",
    "# --- SAVE ---\n",
    "df_filtered.to_csv(output, index=False)\n",
    "\n",
    "print(f\"âœ… Filtered {len(df1)} â†’ {len(df_filtered)} rows.\")\n",
    "print(f\"ðŸ’¾ Saved to: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6a8006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged 5242595 + 2119326 = 7361921 rows\n",
      "ðŸ’¾ Saved to: C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\data\\ais_combined_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG ---\n",
    "file1 = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\data\\ais_combined.csv\")\n",
    "file2 = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\ais_combined_until12_filtered.csv\")\n",
    "output = Path(r\"C:\\Users\\Nikos\\Desktop\\DTU\\Deep Learning\\project\\data\\ais_combined_merged.csv\")\n",
    "\n",
    "# --- READ ---\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# --- MERGE (append vertically) ---\n",
    "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# --- SAVE ---\n",
    "df_merged.to_csv(output, index=False)\n",
    "print(f\"âœ… Merged {len(df1)} + {len(df2)} = {len(df_merged)} rows\")\n",
    "print(f\"ðŸ’¾ Saved to: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095de52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
